{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cancer Cell Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iadNjTwWwwTY",
        "HbWI64yG2wEw",
        "MzeZnwcM3BUg",
        "tB1G6fPU3N7I",
        "rF-G30oySA83"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMBVx2rihDJnAmPww9BPiFk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noy-Bo/Cancer-Cell-Segmentation/blob/master/Cancer_Cell_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iadNjTwWwwTY"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "mounting drive, setting root path to PanNuke dataset, setting device to cuda, checking out GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9G0v8wsgvk",
        "outputId": "1ab9155c-07de-47ba-a323-9cf0375a1bfc"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JnPIOOtM-f"
      },
      "source": [
        "import os\n",
        "root_path = '/content/gdrive/MyDrive/PanNuke/' \n",
        "os.chdir(root_path)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8t0kxy7Z3B",
        "outputId": "afecd8b1-c49a-45c5-91fe-617ab3d90848"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAtxgDvQ7eDJ",
        "outputId": "ea0571f4-73c6-4358-84fb-3a60cdefcae2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 22 21:59:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbWI64yG2wEw"
      },
      "source": [
        "# **Dataset**\n",
        "loading files, creating dataloaders, etc..\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y25bHcYNtcmu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.transforms import transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "class PanNukeDataset(Dataset):\n",
        "    def __init__(self, image_dir, masks_dir=None, cancer_types_dir=None, transform=None):\n",
        "        #self.image_dir = image_dir\n",
        "        #self.masks_dir = masks_dir\n",
        "        #self.cancer_types_dir = cancer_types_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Data is pickled into dictionaries ({'images': imgs, 'cancer_types': cancer_types, 'masks':masks}), let's open it up:\n",
        "        with open(image_dir, mode='rb') as f:  # The with just manages closing of files and etc once finished.\n",
        "            data_dict = pickle.load(f)  # load the original pickled dataset\n",
        "\n",
        "        self.images = data_dict['images']\n",
        "        self.cancer_types = data_dict['cancer_types']\n",
        "        self.masks = data_dict['masks']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    # returns images,masks   FOR NOW IT DOESN'T RETURN cancer_types!!!\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index, ...].astype(dtype=np.float32)\n",
        "        mask = self.masks[index, ...].astype(dtype=np.float32)\n",
        "        mask[mask > 0] = 1.0\n",
        "\n",
        "        # Set dimensions from 256x256xCH, to CHx256x256  - CHECK TO BE POSITIVE\n",
        "        mask = np.moveaxis(mask, -1, 0)\n",
        "        image = np.moveaxis(image, -1, 0)\n",
        "\n",
        "\n",
        "        if self.transform is not None :\n",
        "            augmentation = self.transform(image=image, mask=mask)\n",
        "            image = augmentation[\"image\"]\n",
        "            mask = augmentation[\"mask\"]\n",
        "\n",
        "        return torch.from_numpy(image),torch.from_numpy(mask)\n",
        "\n",
        "# Creating dataloaders\n",
        "def load_dataset(batch_size, shuffle_flag, num_workers, data_dir, transforms=None):\n",
        "  dataset = PanNukeDataset(data_dir)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_flag, num_workers=num_workers)\n",
        "  return data_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzeZnwcM3BUg"
      },
      "source": [
        "# **Model**\n",
        "basic UNet model configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyi6s5FNtjrW"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dblock1 = double_conv(3, 128)\n",
        "        self.dblock2 = double_conv(128, 256)\n",
        "        self.dblock3 = double_conv(256, 512)\n",
        "        self.dblock4 = double_conv(512, 1024)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dblock5 = double_conv(512 + 1024, 512)\n",
        "        self.dblock6 = double_conv(256 + 512, 256)\n",
        "        self.dblock7 = double_conv(256 + 128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.last_layer = nn.Conv2d(128, 6, 1)\n",
        "        #self.last_layer_rly = nn.Conv2d(512,6,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dblock1(x)\n",
        "        x = self.pool(conv1)\n",
        "\n",
        "        conv2 = self.dblock2(x)\n",
        "        x = self.pool(conv2)\n",
        "\n",
        "        conv3 = self.dblock3(x)\n",
        "        x = self.pool(conv3)\n",
        "\n",
        "        conv4 = self.dblock4(x)\n",
        "\n",
        "        x = self.upsample(conv4)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dblock5(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dblock6(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.dblock7(x)\n",
        "\n",
        "        out = self.last_layer(x)\n",
        "        #out = self.last_layer_rly(x)\n",
        "        # out = self.sigmoid(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv_masks = nn.Conv2d(in_channels=features, out_channels=6, kernel_size=1)\n",
        "\n",
        "        # self.conv = nn.Conv2d(\n",
        "        #     in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        # )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc1 = self.dropout(enc1)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc2 = self.dropout(enc2)\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc3 = self.dropout(enc3)\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "        enc4 = self.dropout(enc4)\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "        bottleneck = self.dropout(bottleneck)\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec4 = self.dropout(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec3 = self.dropout(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec2 = self.dropout(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        dec1 = self.dropout(dec1)\n",
        "        #return torch.sigmoid(self.conv(dec1))\n",
        "        return torch.sigmoid(self.conv_masks(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgIv6ChUp7ks"
      },
      "source": [
        "# **Data Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZqli-QWqAMz"
      },
      "source": [
        "\n",
        "# calc normalization values of given data loader\n",
        "def calc_normalization(data_loader):\n",
        "    pop_mean = []\n",
        "    pop_std0 = []\n",
        "    pop_std1 = []\n",
        "    for idx_batch, (images, masks) in enumerate(data_loader, 0):\n",
        "     # shape (batch_size, 3, height, width)\n",
        "     numpy_image = images.numpy()\n",
        "\n",
        "     # shape (3,)\n",
        "     batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
        "     batch_std0 = np.std(numpy_image, axis=(0, 2, 3))\n",
        "     batch_std1 = np.std(numpy_image, axis=(0, 2, 3), ddof=1)\n",
        "\n",
        "     pop_mean.append(batch_mean/255)\n",
        "     pop_std0.append(batch_std0/255)\n",
        "     pop_std1.append(batch_std1/255)\n",
        "\n",
        "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
        "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
        "    print(pop_mean)\n",
        "    pop_std0 = np.array(pop_std0).mean(axis=0)\n",
        "    print(pop_std0)\n",
        "    pop_std1 = np.array(pop_std1).mean(axis=0)\n",
        "    print(pop_std1)\n",
        "\n",
        "\n",
        "# VISUALIZING SAMPLES - designed for input that is the dataloader output, for raw input cancel moveaxis\n",
        "def vis_sample(image, masks):\n",
        "    fig, axs = plt.subplots(1,7)\n",
        "    fig.set_size_inches(18.5, 3.2)\n",
        "    fig.suptitle('Ground Truth', fontsize=18)\n",
        "    #fig.tight_layout()\n",
        "    axs[0].imshow(np.moveaxis(image.cpu().detach().numpy().astype(np.uint8),0,-1)); axs[0].set_title(\"Sample\")\n",
        "    masks = np.moveaxis(masks.cpu().detach().numpy().astype(np.uint8),0,-1)\n",
        "    axs[1].imshow(masks[:,:,0], cmap=\"gray\"); axs[1].set_title(\"Neoplastic cells\")\n",
        "    axs[2].imshow(masks[:,:,1], cmap=\"gray\"); axs[2].set_title(\"Inflammatory\")\n",
        "    axs[3].imshow(masks[:,:,2], cmap=\"gray\"); axs[3].set_title(\"Connective/Soft tissue cells\")\n",
        "    axs[4].imshow(masks[:,:,3], cmap=\"gray\"); axs[4].set_title(\"Dead Cells\")\n",
        "    axs[5].imshow(masks[:,:,4], cmap=\"gray\"); axs[5].set_title(\"Epithelial\")\n",
        "    axs[6].imshow(masks[:,:,5], cmap=\"gray\"); axs[6].set_title(\"Background\")\n",
        "    plt.show()\n",
        "\n",
        "# VISUALIZING PREDICTIONS - visualizing network output on a random sample.\n",
        "def vis_predictions():\n",
        "    image_gt_batch, masks_gt_batch = iter(training_loader_1).next()\n",
        "    pred_masks_batch = model(image_gt_batch)\n",
        "    for i in range(image_gt_batch.shape[0]): # looping on batch_size\n",
        "      print(\"\\n\\n\")\n",
        "      print(\"\\t\\t\\t\\t\\t\\t\\t\\t SAMPLE: {}\".format(str(i)))\n",
        "      image = image_gt_batch[i,...] # 3,256,256\n",
        "      pred_masks = pred_masks_batch[i,...] # 6,256,256\n",
        "\n",
        "      fig, axs = plt.subplots(1,7)\n",
        "      fig.set_size_inches(18.5, 3.3)\n",
        "      fig.suptitle('Prediction', fontsize=18)\n",
        "      #fig.tight_layout()\n",
        "      axs[0].imshow(np.moveaxis(image.cpu().detach().numpy().astype(np.uint8),0,-1)); axs[0].set_title(\"Sample\")\n",
        "      axs[1].imshow(pred_masks[0,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[1].set_title(\"Neoplastic cells\")\n",
        "      axs[2].imshow(pred_masks[1,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[2].set_title(\"Inflammatory\")\n",
        "      axs[3].imshow(pred_masks[2,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[3].set_title(\"Connective/Soft tissue cells\")\n",
        "      axs[4].imshow(pred_masks[3,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[4].set_title(\"Dead Cells\")\n",
        "      axs[5].imshow(pred_masks[4,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[5].set_title(\"Epithelial\")\n",
        "      axs[6].imshow(pred_masks[5,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[6].set_title(\"Background\")\n",
        "      plt.show()\n",
        "\n",
        "      vis_sample(image,masks_gt_batch[i,...]) # visualizing gt (ground truth)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB1G6fPU3N7I"
      },
      "source": [
        "# **Train Utilities**\n",
        "loss functions configurations, train epoch function ..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsxsKcFftmZu",
        "outputId": "6b2c5add-95ed-4c08-f426-d1af49a48fc2"
      },
      "source": [
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)\n",
        "\n",
        "\n",
        "def CE(predict, target):\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
        "    loss = 0\n",
        "    target =  torch.argmax(target, dim=1)\n",
        "    loss += cross_entropy(predict,target)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_epoch(training_loader, model, optimizer, loss_function, overfit=False, images=None, masks=None,vis=False):\n",
        "\n",
        "    losses = []\n",
        "    model.train()\n",
        "    with tqdm.tqdm(total=len(training_loader), file=sys.stdout) as pbar:\n",
        "        for (images, masks) in training_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # calculate output\n",
        "            y_hat = model(images)\n",
        "\n",
        "            # calculate loss now:\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_function(y_hat, masks)\n",
        "            loss.backward()\n",
        "\n",
        "            # optimizing weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # update loss bar\n",
        "            losses.append(loss.detach())\n",
        "            pbar.update();\n",
        "            pbar.set_description(f'train loss={losses[-1]:.3f}')\n",
        "        mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "        pbar.set_description(f'train loss={mean_loss:.3f}')\n",
        "\n",
        "        images = None\n",
        "        masks = None\n",
        "    return [mean_loss]\n",
        "\n",
        "    \n",
        "def eval_loss_epoch(training_loader, model, loss_function):\n",
        "\n",
        "    losses = []\n",
        "    model.eval()\n",
        "    with tqdm.tqdm(total=len(training_loader), file=sys.stdout) as pbar:\n",
        "        for idx_batch, (images, masks) in enumerate(training_loader, start=1):\n",
        "\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # calculate output\n",
        "            y_hat = model(images)\n",
        "\n",
        "            # calculate loss now:\n",
        "            loss = loss_function(y_hat, masks)\n",
        "\n",
        "            # optimizing weights\n",
        "\n",
        "            # update loss bar\n",
        "            losses.append(loss.detach())\n",
        "            pbar.update();\n",
        "            pbar.set_description(f'val loss={losses[-1]:.3f}')\n",
        "\n",
        "            images = None\n",
        "            masks = None\n",
        "        mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "        pbar.set_description(f'val loss={mean_loss:.3f}')\n",
        "\n",
        "    return mean_loss\n",
        "\n",
        "    \n",
        "def train_on_1_batch(model, optimizer, loss_function, images, masks,vis=False):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "    pred_masks_batch = model(images)\n",
        "    for i in range(images.shape[0]): # looping on batch_size\n",
        "      image = images[i,...] # 3,256,256\n",
        "      pred_masks = pred_masks_batch[i,...]\n",
        "      one_hot_masks = torch.nn.functional.one_hot(torch.argmax(pred_masks, dim=0))\n",
        "      one_hot_masks = one_hot_masks.permute(2,0,1)\n",
        "      one_hot_masks *= 250 # white color?\n",
        "\n",
        "      if vis is True:\n",
        "        print(\"\\n\\n\")\n",
        "        print(\"\\t\\t\\t\\t\\t\\t\\t\\t SAMPLE: {}\".format(str(i)))\n",
        "        fig, axs = plt.subplots(1,7)\n",
        "        fig.set_size_inches(18.5, 3.3)\n",
        "        fig.suptitle('Prediction', fontsize=18)\n",
        "        #fig.tight_layout()\n",
        "        axs[0].imshow(np.moveaxis(image.cpu().detach().numpy().astype(np.uint8),0,-1)); axs[0].set_title(\"Sample\")\n",
        "        axs[1].imshow(one_hot_masks[0,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[1].set_title(\"Neoplastic cells\")\n",
        "        axs[2].imshow(one_hot_masks[1,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[2].set_title(\"Inflammatory\")\n",
        "        axs[3].imshow(one_hot_masks[2,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[3].set_title(\"Connective/Soft tissue cells\")\n",
        "        axs[4].imshow(one_hot_masks[3,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[4].set_title(\"Dead Cells\")\n",
        "        axs[5].imshow(one_hot_masks[4,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[5].set_title(\"Epithelial\")\n",
        "        axs[6].imshow(one_hot_masks[5,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[6].set_title(\"Background\")\n",
        "        plt.show()\n",
        "\n",
        "        vis_sample(image,masks[i,...]) # visualizing gt (ground truth)\n",
        "    #calculate output\n",
        "    y_hat = model(images)\n",
        "\n",
        "    # calculate loss now:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(y_hat, masks)\n",
        "    loss.backward()\n",
        "\n",
        "    # optimizing weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # update loss bar\n",
        "    losses.append(loss.detach())\n",
        "    mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "    return mean_loss\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ljco_YporiS"
      },
      "source": [
        "# **Creating Data Loaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_In21viozb5"
      },
      "source": [
        "train_dir = '/content/gdrive/MyDrive/Dataset/train_pickled_data'\n",
        "val_dir = '/content/gdrive/MyDrive/Dataset/val_pickled_data'\n",
        "test_dir = '/content/gdrive/MyDrive/Dataset/test_pickled_data'\n",
        "# Grab loaders:\n",
        "#load_dataset(2,None,None,None)\n",
        "validation_loader = load_dataset(batch_size=12, shuffle_flag=True, num_workers=4, data_dir=val_dir)\n",
        "test_loader = load_dataset(batch_size=12, shuffle_flag=True, num_workers=4, data_dir=test_dir)\n",
        "training_loader = load_dataset(batch_size=12, shuffle_flag=True, num_workers=4, data_dir=train_dir)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCVfGIl3jiZ"
      },
      "source": [
        "# **Main (training)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t83yC39t7sH",
        "outputId": "4462e511-ea9a-4c07-f659-f4dfe70121ea"
      },
      "source": [
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# creating model\n",
        "model = Unet().to(device)\n",
        "summary(model, (3,256,256))\n",
        "\n",
        "# # visualization sample              # save every RAM we have!\n",
        "# image, masks = iter(training_loader_1).next()\n",
        "# vis_sample(image[0,...], masks[0,...])\n",
        "\n",
        "# config training\n",
        "epochs = 500\n",
        "loss_function = CE\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9,0.999), eps =1e-08)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.9)\n",
        "\n",
        "\n",
        "PATH = root_path + \"model_UNet.pt\"\n",
        "min_val_loss = np.inf\n",
        "# training\n",
        "for i in range (1,epochs):\n",
        " print(\"=========================== EPOCH: {} ===========================\".format(str(i)))\n",
        " print(\"TRAIN LOSS:\")\n",
        " #train_epoch(training_loader=training_loader, model=model, optimizer=optimizer, loss_function=loss_function, overfit=True, images=image_batch, masks=masks_batch, vis=vis)\n",
        " train_epoch(training_loader=training_loader, model=model, optimizer=optimizer, loss_function=loss_function)\n",
        " print(\"VAL LOSS:\")\n",
        " val_loss = eval_loss_epoch(training_loader=validation_loader, model=model, loss_function=loss_function)\n",
        " scheduler.step()\n",
        " if val_loss < min_val_loss:\n",
        "   torch.save(model, PATH)\n",
        "   min_val_loss = val_loss\n",
        " \n",
        " #vis_predictions()\n",
        "\n",
        "# loading model\n",
        "model = UNet().to(device)\n",
        "model = torch.load(PATH)\n",
        "\n",
        "# visualizing predictions\n",
        "vis_predictions()\n",
        "\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 256, 256]           3,584\n",
            "              ReLU-2        [-1, 128, 256, 256]               0\n",
            "            Conv2d-3        [-1, 128, 256, 256]         147,584\n",
            "              ReLU-4        [-1, 128, 256, 256]               0\n",
            "         MaxPool2d-5        [-1, 128, 128, 128]               0\n",
            "            Conv2d-6        [-1, 256, 128, 128]         295,168\n",
            "              ReLU-7        [-1, 256, 128, 128]               0\n",
            "            Conv2d-8        [-1, 256, 128, 128]         590,080\n",
            "              ReLU-9        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-10          [-1, 256, 64, 64]               0\n",
            "           Conv2d-11          [-1, 512, 64, 64]       1,180,160\n",
            "             ReLU-12          [-1, 512, 64, 64]               0\n",
            "           Conv2d-13          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-14          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-15          [-1, 512, 32, 32]               0\n",
            "           Conv2d-16         [-1, 1024, 32, 32]       4,719,616\n",
            "             ReLU-17         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-18         [-1, 1024, 32, 32]       9,438,208\n",
            "             ReLU-19         [-1, 1024, 32, 32]               0\n",
            "         Upsample-20         [-1, 1024, 64, 64]               0\n",
            "           Conv2d-21          [-1, 512, 64, 64]       7,078,400\n",
            "             ReLU-22          [-1, 512, 64, 64]               0\n",
            "           Conv2d-23          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-24          [-1, 512, 64, 64]               0\n",
            "         Upsample-25        [-1, 512, 128, 128]               0\n",
            "           Conv2d-26        [-1, 256, 128, 128]       1,769,728\n",
            "             ReLU-27        [-1, 256, 128, 128]               0\n",
            "           Conv2d-28        [-1, 256, 128, 128]         590,080\n",
            "             ReLU-29        [-1, 256, 128, 128]               0\n",
            "         Upsample-30        [-1, 256, 256, 256]               0\n",
            "           Conv2d-31        [-1, 128, 256, 256]         442,496\n",
            "             ReLU-32        [-1, 128, 256, 256]               0\n",
            "           Conv2d-33        [-1, 128, 256, 256]         147,584\n",
            "             ReLU-34        [-1, 128, 256, 256]               0\n",
            "           Conv2d-35          [-1, 6, 256, 256]             774\n",
            "================================================================\n",
            "Total params: 31,123,078\n",
            "Trainable params: 31,123,078\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 1183.00\n",
            "Params size (MB): 118.73\n",
            "Estimated Total Size (MB): 1302.48\n",
            "----------------------------------------------------------------\n",
            "=========================== EPOCH: 1 ===========================\n",
            "TRAIN LOSS:\n",
            "\r  0%|          | 0/527 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss=0.517: 100%|██████████| 527/527 [07:05<00:00,  1.24it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.606: 100%|██████████| 66/66 [00:21<00:00,  3.06it/s]\n",
            "=========================== EPOCH: 2 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.448: 100%|██████████| 527/527 [07:16<00:00,  1.21it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.584: 100%|██████████| 66/66 [00:21<00:00,  3.07it/s]\n",
            "=========================== EPOCH: 3 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.384: 100%|██████████| 527/527 [07:16<00:00,  1.21it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.438: 100%|██████████| 66/66 [00:21<00:00,  3.06it/s]\n",
            "=========================== EPOCH: 4 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.347: 100%|██████████| 527/527 [07:16<00:00,  1.21it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.487: 100%|██████████| 66/66 [00:21<00:00,  3.07it/s]\n",
            "=========================== EPOCH: 5 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.321: 100%|██████████| 527/527 [07:16<00:00,  1.21it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.405: 100%|██████████| 66/66 [00:21<00:00,  3.07it/s]\n",
            "=========================== EPOCH: 6 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.313: 100%|██████████| 527/527 [07:16<00:00,  1.21it/s]\n",
            "VAL LOSS:\n",
            "val loss=0.378: 100%|██████████| 66/66 [00:21<00:00,  3.07it/s]\n",
            "=========================== EPOCH: 7 ===========================\n",
            "TRAIN LOSS:\n",
            "train loss=0.283:   9%|▉         | 47/527 [00:39<06:37,  1.21it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF-G30oySA83"
      },
      "source": [
        "# **Visualizing Predictions vs Ground Truth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpMogAqiSH8w"
      },
      "source": [
        "#saving model\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# torch.save(model, PATH)\n",
        "\n",
        "# model = UNet().to(device)\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# model = torch.load(PATH)\n",
        "\n",
        "vis_predictions()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxCNIyFP1Hor"
      },
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}