{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cancer Cell Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iadNjTwWwwTY",
        "MzeZnwcM3BUg",
        "tB1G6fPU3N7I",
        "rF-G30oySA83"
      ],
      "authorship_tag": "ABX9TyP8LfYxCt28LSRsAKUSk4Ev",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noy-Bo/Cancer-Cell-Segmentation/blob/master/Cancer_Cell_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iadNjTwWwwTY"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "mounting drive, setting root path to PanNuke dataset, setting device to cuda, checking out GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9G0v8wsgvk",
        "outputId": "2dcb21fd-befd-46aa-af85-bf64c2fd0526"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JnPIOOtM-f"
      },
      "source": [
        "import os\n",
        "root_path = '/content/gdrive/MyDrive/PanNuke' \n",
        "os.chdir(root_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8t0kxy7Z3B",
        "outputId": "5b673c7e-b771-4393-e630-570fa54dad1e"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAtxgDvQ7eDJ",
        "outputId": "07114bcf-ca96-4d99-b743-deaa525a0371"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 21 18:02:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbWI64yG2wEw"
      },
      "source": [
        "# **Dataset**\n",
        "loading files, creating dataloaders, etc..\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y25bHcYNtcmu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "# calc normalization values of given data loader\n",
        "def calc_normalization(data_loader):\n",
        "    pop_mean = []\n",
        "    pop_std0 = []\n",
        "    pop_std1 = []\n",
        "    for idx_batch, (images, masks) in enumerate(data_loader, 0):\n",
        "     # shape (batch_size, 3, height, width)\n",
        "     numpy_image = images.numpy()\n",
        "\n",
        "     # shape (3,)\n",
        "     batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
        "     batch_std0 = np.std(numpy_image, axis=(0, 2, 3))\n",
        "     batch_std1 = np.std(numpy_image, axis=(0, 2, 3), ddof=1)\n",
        "\n",
        "     pop_mean.append(batch_mean/255)\n",
        "     pop_std0.append(batch_std0/255)\n",
        "     pop_std1.append(batch_std1/255)\n",
        "\n",
        "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
        "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
        "    print(pop_mean)\n",
        "    pop_std0 = np.array(pop_std0).mean(axis=0)\n",
        "    print(pop_std0)\n",
        "    pop_std1 = np.array(pop_std1).mean(axis=0)\n",
        "    print(pop_std1)\n",
        "\n",
        "\n",
        "# VISUALIZING SAMPLES - designed for input that is the dataloader output, for raw input cancel moveaxis\n",
        "def vis_sample(image, masks):\n",
        "    fig, axs = plt.subplots(1,7)\n",
        "    fig.set_size_inches(18.5, 3.2)\n",
        "    fig.suptitle('Ground Truth', fontsize=18)\n",
        "    #fig.tight_layout()\n",
        "    axs[0].imshow(np.moveaxis(image.numpy().astype(np.uint8),0,-1)); axs[0].set_title(\"Sample\")\n",
        "    masks = np.moveaxis(masks.numpy().astype(np.uint8),0,-1)\n",
        "    axs[1].imshow(masks[:,:,0], cmap=\"gray\"); axs[1].set_title(\"Neoplastic cells\")\n",
        "    axs[2].imshow(masks[:,:,1], cmap=\"gray\"); axs[2].set_title(\"Inflammatory\")\n",
        "    axs[3].imshow(masks[:,:,2], cmap=\"gray\"); axs[3].set_title(\"Connective/Soft tissue cells\")\n",
        "    axs[4].imshow(masks[:,:,3], cmap=\"gray\"); axs[4].set_title(\"Dead Cells\")\n",
        "    axs[5].imshow(masks[:,:,4], cmap=\"gray\"); axs[5].set_title(\"Epithelial\")\n",
        "    #axs[6].imshow(masks[:,:,5], cmap=\"gray\"); axs[6].set_title(\"Background\")\n",
        "    plt.show()\n",
        "\n",
        "# VISUALIZING PREDICTIONS - visualizing network output on a random sample.\n",
        "def vis_predictions():\n",
        "    image_gt_batch, masks_gt_batch = iter(training_loader_1).next()\n",
        "    pred_masks_batch = model(image_gt_batch)\n",
        "    for i in range(image_gt_batch.shape[0]): # looping on batch_size\n",
        "      print(\"\\n\\n\")\n",
        "      print(\"\\t\\t\\t\\t\\t\\t\\t\\t SAMPLE: {}\".format(str(i)))\n",
        "      image = image_gt_batch[i,...] # 3,256,256\n",
        "      pred_masks = pred_masks_batch[i,...] # 6,256,256\n",
        "\n",
        "      fig, axs = plt.subplots(1,7)\n",
        "      fig.set_size_inches(18.5, 3.3)\n",
        "      fig.suptitle('Prediction', fontsize=18)\n",
        "      #fig.tight_layout()\n",
        "      axs[0].imshow(np.moveaxis(image.numpy().astype(np.uint8),0,-1)); axs[0].set_title(\"Sample\")\n",
        "      axs[1].imshow(pred_masks[0,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[1].set_title(\"Neoplastic cells\")\n",
        "      axs[2].imshow(pred_masks[1,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[2].set_title(\"Inflammatory\")\n",
        "      axs[3].imshow(pred_masks[2,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[3].set_title(\"Connective/Soft tissue cells\")\n",
        "      axs[4].imshow(pred_masks[3,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[4].set_title(\"Dead Cells\")\n",
        "      axs[5].imshow(pred_masks[4,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[5].set_title(\"Epithelial\")\n",
        "      #axs[6].imshow(pred_masks[5,:,:].cpu().detach().numpy(), cmap=\"gray\"); axs[6].set_title(\"Background\")\n",
        "      plt.show()\n",
        "\n",
        "      vis_sample(image,masks_gt_batch[i,...]) # visualizing gt (ground truth)\n",
        "\n",
        "\n",
        "# LOADING DATASET\n",
        "def load_dataset(dir_root, dir_images, dir_masks, training_size=0.8):\n",
        "\n",
        "    train_set = PanNuke(dir_root, dir_images, dir_masks, train=True)\n",
        "\n",
        "    # Splitting train into train/val\n",
        "    permutations = torch.randperm(len(train_set))\n",
        "    split = int(np.floor(training_size * len(train_set)))\n",
        "    training_subset = SubsetRandomSampler(permutations[:split])\n",
        "    validation_subset = SubsetRandomSampler(permutations[split:])\n",
        "\n",
        "    # Apply DataLoader over train val and test data\n",
        "    train_loader = DataLoader(train_set, sampler=training_subset, batch_size=1, num_workers=4)\n",
        "    validation_loader = DataLoader(train_set, sampler=validation_subset, batch_size=1, num_workers=4)\n",
        "\n",
        "    return train_loader, validation_loader\n",
        "\n",
        "\n",
        "\n",
        "# DATASET CLASS\n",
        "class PanNuke(Dataset):\n",
        "    def __init__(self, dir_root, dir_images, dir_masks, val=False, train=False, test=False):\n",
        "        self.images = np.load(dir_root+dir_images, mmap_mode='r')\n",
        "        self.images = np.moveaxis(self.images, -1, 1)\n",
        "        #self.images = np.copy(self.images)\n",
        "        self.masks = np.load(dir_root+dir_masks, mmap_mode='r')\n",
        "        self.masks = np.moveaxis(self.masks, -1, 1)\n",
        "        #self.masks = np.copy(self.masks)\n",
        "        self.masks = self.masks[:,:5,...]\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "            #transforms.Normalize(mean=[0.73952988, 0.5701334, 0.702605], std=[0.18024648, 0.21097612, 0.16465892 ])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.copy(self.images[idx, ...])\n",
        "        img = self.transforms(img.transpose())\n",
        "        masks = np.copy(self.masks[idx, ...])\n",
        "        masks = np.ceil(masks/1000)\n",
        "        return img, masks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzeZnwcM3BUg"
      },
      "source": [
        "# **Model**\n",
        "basic UNet model configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyi6s5FNtjrW"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dblock1 = double_conv(3, 128)\n",
        "        self.dblock2 = double_conv(128, 256)\n",
        "        self.dblock3 = double_conv(256, 512)\n",
        "        self.dblock4 = double_conv(512, 1024)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dblock5 = double_conv(512 + 1024, 512)\n",
        "        self.dblock6 = double_conv(256 + 512, 256)\n",
        "        self.dblock7 = double_conv(256 + 128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.last_layer = nn.Conv2d(128, 512, 1)\n",
        "        self.last_layer_rly = nn.Conv2d(512,5,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dblock1(x)\n",
        "        x = self.pool(conv1)\n",
        "\n",
        "        conv2 = self.dblock2(x)\n",
        "        x = self.pool(conv2)\n",
        "\n",
        "        conv3 = self.dblock3(x)\n",
        "        x = self.pool(conv3)\n",
        "\n",
        "        conv4 = self.dblock4(x)\n",
        "\n",
        "        x = self.upsample(conv4)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dblock5(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dblock6(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.dblock7(x)\n",
        "\n",
        "        x = self.last_layer(x)\n",
        "        out = self.last_layer_rly(x)\n",
        "        # out = self.sigmoid(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv_masks = nn.Conv2d(in_channels=features, out_channels=5, kernel_size=1)\n",
        "\n",
        "        # self.conv = nn.Conv2d(\n",
        "        #     in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        # )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc1 = self.dropout(enc1)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc2 = self.dropout(enc2)\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc3 = self.dropout(enc3)\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "        enc4 = self.dropout(enc4)\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "        bottleneck = self.dropout(bottleneck)\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec4 = self.dropout(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec3 = self.dropout(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec2 = self.dropout(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        dec1 = self.dropout(dec1)\n",
        "        #return torch.sigmoid(self.conv(dec1))\n",
        "        return torch.sigmoid(self.conv_masks(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB1G6fPU3N7I"
      },
      "source": [
        "# **Train Utilities**\n",
        "loss functions configurations, train epoch function ..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsxsKcFftmZu",
        "outputId": "2bbc8342-e710-497b-c909-d90803c2738b"
      },
      "source": [
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)\n",
        "\n",
        "def dice_loss(predict, target):\n",
        "    smooth = 1.\n",
        "    loss = 0.\n",
        "    for c in range(predict.shape[1]):\n",
        "        iflat = predict[:, c, ...].contiguous().view(-1)\n",
        "        tflat = target[:, c, ...].contiguous().view(-1)\n",
        "        intersection = (iflat * tflat).sum()\n",
        "\n",
        "        loss +=  (1 - ((2. * intersection + smooth) /\n",
        "                          (iflat.sum() + tflat.sum() + smooth)))\n",
        "    return loss\n",
        "def BCE(predict, target):\n",
        "    loss_func = nn.BCELoss()\n",
        "    softmax = torch.nn.Softmax(dim=0)\n",
        "    assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
        "    loss = 0\n",
        "    predict = predict.permute(0,2,3,1)\n",
        "    predict = predict.flatten()\n",
        "    predict = predict.reshape(5,-1)\n",
        "    predict = softmax(predict)\n",
        "    target = target.permute(0,2,3,1)\n",
        "    target = target.flatten()\n",
        "    target = target.reshape(5,-1)\n",
        "\n",
        "    loss += loss_func(predict,target)\n",
        "    return loss\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    \"\"\"Dice loss of binary class\n",
        "    Args:\n",
        "        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n",
        "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n",
        "        predict: A tensor of shape [N, *]\n",
        "        target: A tensor of shape same with predict\n",
        "        reduction: Reduction method to apply, return mean over batch if 'mean',\n",
        "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
        "    Returns:\n",
        "        Loss tensor according to arg reduction\n",
        "    Raise:\n",
        "        Exception if unexpected reduction\n",
        "    \"\"\"\n",
        "    def __init__(self, smooth=1, p=2, reduction='sum'):\n",
        "        super(BinaryDiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
        "        loss = 0\n",
        "        for b_idx in range(predict.shape[0]):\n",
        "            for m_idx in range(predict.shape[1]):\n",
        "                predict_i = predict[b_idx,m_idx,...].contiguous().view(-1)\n",
        "                target_i = target[b_idx,m_idx,...].contiguous().view(-1)\n",
        "\n",
        "                num = torch.sum(torch.mul(predict_i, target_i), dim=0) + self.smooth\n",
        "                den = torch.sum(predict_i.pow(self.p) + target_i.pow(self.p), dim=0) + self.smooth\n",
        "\n",
        "                loss = loss +  1 - num / den\n",
        "\n",
        "        # predict = predict.contiguous().view(predict.shape[0], -1)\n",
        "        # target = target.contiguous().view(target.shape[0], -1)\n",
        "\n",
        "        # num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n",
        "        # den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n",
        "        #\n",
        "        # loss = 1 - num / den\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            return loss\n",
        "        else:\n",
        "            raise Exception('Unexpected reduction {}'.format(self.reduction))\n",
        "\n",
        "\n",
        "def train_epoch(training_loader, model, optimizer, loss_function, overfit=False, images=None, masks=None):\n",
        "\n",
        "    losses = []\n",
        "    model.train()\n",
        "    if overfit is True:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # calculate output\n",
        "        y_hat = model(images)\n",
        "\n",
        "        # calculate loss now:\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_function(y_hat, masks)\n",
        "        loss.backward()\n",
        "\n",
        "        # optimizing weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # update loss bar\n",
        "        losses.append(loss.detach())\n",
        "        mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "        print(mean_loss)\n",
        "        return mean_loss\n",
        "    with tqdm.tqdm(total=len(training_loader), file=sys.stdout) as pbar:\n",
        "        for idx_batch, (images, masks) in enumerate(training_loader, start=1):\n",
        "\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # calculate output\n",
        "            y_hat = model(images)\n",
        "\n",
        "            # calculate loss now:\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_function(y_hat, masks)\n",
        "            loss.backward()\n",
        "\n",
        "            # optimizing weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # update loss bar\n",
        "            losses.append(loss.detach())\n",
        "            pbar.update();\n",
        "            pbar.set_description(f'train loss={losses[-1]:.3f}')\n",
        "        mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "        pbar.set_description(f'train loss={mean_loss:.3f}')\n",
        "\n",
        "        images = None\n",
        "        masks = None\n",
        "    return [mean_loss]\n",
        "\n",
        "    \n",
        "def eval_loss_epoch(training_loader, model, loss_function):\n",
        "\n",
        "    losses = []\n",
        "    model.eval()\n",
        "    with tqdm.tqdm(total=len(training_loader), file=sys.stdout) as pbar:\n",
        "        for idx_batch, (images, masks) in enumerate(training_loader, start=1):\n",
        "\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # calculate output\n",
        "            y_hat = model(images)\n",
        "\n",
        "            # calculate loss now:\n",
        "            loss = loss_function(y_hat, masks)\n",
        "\n",
        "            # optimizing weights\n",
        "\n",
        "            # update loss bar\n",
        "            losses.append(loss.detach())\n",
        "            pbar.update();\n",
        "            pbar.set_description(f'val loss={losses[-1]:.3f}')\n",
        "\n",
        "            images = None\n",
        "            masks = None\n",
        "        mean_loss = torch.mean(torch.FloatTensor(losses))\n",
        "        pbar.set_description(f'val loss={mean_loss:.3f}')\n",
        "\n",
        "    return [mean_loss]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCVfGIl3jiZ"
      },
      "source": [
        "# **Main (training)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-t83yC39t7sH",
        "outputId": "54896b4f-01bf-4af6-a048-7049900f7369"
      },
      "source": [
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# creating data loaders\n",
        "images_dir = 'Images 1/images.npy'\n",
        "masks_dir = 'Masks 1/masks.npy'\n",
        "training_loader_1, _ = load_dataset(dir_root='', dir_masks=masks_dir, dir_images=images_dir, training_size=1)\n",
        "images_dir = 'Images 3/images.npy'\n",
        "masks_dir = 'Masks 3/masks.npy'\n",
        "training_loader_2, _ = load_dataset(dir_root='', dir_masks=masks_dir, dir_images=images_dir, training_size=1)\n",
        "images_dir = 'Images 2/images.npy'\n",
        "masks_dir = 'Masks 2/masks.npy'\n",
        "validation_loader, test_loader = load_dataset(dir_root='', dir_masks=masks_dir, dir_images=images_dir, training_size=0.5)\n",
        "\n",
        "# creating model\n",
        "model = Unet().to(device)\n",
        "summary(model, (3,256,256))\n",
        "model.double()\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# model = torch.load(PATH)\n",
        "\n",
        "# # visualization sample              # save every RAM we have!\n",
        "# image, masks = iter(training_loader_1).next()\n",
        "# vis_sample(image[0,...], masks[0,...])\n",
        "\n",
        "# config training\n",
        "epochs = 100\n",
        "loss_function = BCE\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.999), eps =1e-08)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.9)\n",
        "\n",
        "\n",
        "# overfitting test\n",
        "image_batch, masks_batch = iter(training_loader_1).next()\n",
        "\n",
        "# training\n",
        "for i in range (1,epochs):\n",
        " print(\"=========================== EPOCH: {} ===========================\".format(str(i)))\n",
        " print(\"TRAIN LOSS:\")\n",
        " train_epoch(training_loader=training_loader_1, model=model, optimizer=optimizer, loss_function=loss_function, overfit=True, images=image_batch, masks=masks_batch)\n",
        " #train_epoch(training_loader=training_loader_2, model=model, optimizer=optimizer, loss_function=loss_function)\n",
        " print(\"VAL LOSS:\")\n",
        " #eval_loss_epoch(training_loader=validation_loader, model=model, loss_function=loss_function)\n",
        " #scheduler.step()\n",
        " #vis_predictions()\n",
        "\n",
        "# saving model\n",
        "PATH = root_path + \"/model_UNet.pt\"\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# loading model\n",
        "model = UNet().to(device)\n",
        "model = torch.load(PATH)\n",
        "\n",
        "# visualizing predictions\n",
        "vis_predictions()\n",
        "\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 256, 256]           3,584\n",
            "              ReLU-2        [-1, 128, 256, 256]               0\n",
            "            Conv2d-3        [-1, 128, 256, 256]         147,584\n",
            "              ReLU-4        [-1, 128, 256, 256]               0\n",
            "         MaxPool2d-5        [-1, 128, 128, 128]               0\n",
            "            Conv2d-6        [-1, 256, 128, 128]         295,168\n",
            "              ReLU-7        [-1, 256, 128, 128]               0\n",
            "            Conv2d-8        [-1, 256, 128, 128]         590,080\n",
            "              ReLU-9        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-10          [-1, 256, 64, 64]               0\n",
            "           Conv2d-11          [-1, 512, 64, 64]       1,180,160\n",
            "             ReLU-12          [-1, 512, 64, 64]               0\n",
            "           Conv2d-13          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-14          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-15          [-1, 512, 32, 32]               0\n",
            "           Conv2d-16         [-1, 1024, 32, 32]       4,719,616\n",
            "             ReLU-17         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-18         [-1, 1024, 32, 32]       9,438,208\n",
            "             ReLU-19         [-1, 1024, 32, 32]               0\n",
            "         Upsample-20         [-1, 1024, 64, 64]               0\n",
            "           Conv2d-21          [-1, 512, 64, 64]       7,078,400\n",
            "             ReLU-22          [-1, 512, 64, 64]               0\n",
            "           Conv2d-23          [-1, 512, 64, 64]       2,359,808\n",
            "             ReLU-24          [-1, 512, 64, 64]               0\n",
            "         Upsample-25        [-1, 512, 128, 128]               0\n",
            "           Conv2d-26        [-1, 256, 128, 128]       1,769,728\n",
            "             ReLU-27        [-1, 256, 128, 128]               0\n",
            "           Conv2d-28        [-1, 256, 128, 128]         590,080\n",
            "             ReLU-29        [-1, 256, 128, 128]               0\n",
            "         Upsample-30        [-1, 256, 256, 256]               0\n",
            "           Conv2d-31        [-1, 128, 256, 256]         442,496\n",
            "             ReLU-32        [-1, 128, 256, 256]               0\n",
            "           Conv2d-33        [-1, 128, 256, 256]         147,584\n",
            "             ReLU-34        [-1, 128, 256, 256]               0\n",
            "           Conv2d-35        [-1, 512, 256, 256]          66,048\n",
            "           Conv2d-36          [-1, 5, 256, 256]           2,565\n",
            "================================================================\n",
            "Total params: 31,190,917\n",
            "Trainable params: 31,190,917\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 1438.50\n",
            "Params size (MB): 118.98\n",
            "Estimated Total Size (MB): 1558.23\n",
            "----------------------------------------------------------------\n",
            "=========================== EPOCH: 1 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2540)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 2 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(18.0818)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 3 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(4.2479)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 4 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.3586)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 5 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2596)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 6 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.3085)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 7 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.7354)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 8 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2913)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 9 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2859)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 10 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2714)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 11 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2648)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 12 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2592)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 13 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2592)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 14 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2555)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 15 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2884)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 16 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2581)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 17 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2598)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 18 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2601)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 19 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2595)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 20 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2583)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 21 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2563)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 22 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2540)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 23 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2549)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 24 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2563)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 25 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2543)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 26 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2532)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 27 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2534)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 28 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2538)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 29 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2536)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 30 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2534)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 31 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2532)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 32 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2537)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 33 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2531)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 34 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2526)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 35 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2525)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 36 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2526)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 37 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2524)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 38 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2520)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 39 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2514)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 40 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2509)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 41 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2501)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 42 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2491)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 43 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2484)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 44 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2484)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 45 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2479)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 46 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2484)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 47 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2496)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 48 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2501)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 49 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2501)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 50 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2493)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 51 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2500)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 52 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2494)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 53 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2490)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 54 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2489)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 55 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2476)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 56 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2473)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 57 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2478)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 58 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2466)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 59 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2472)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 60 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2473)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 61 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2466)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 62 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2463)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 63 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2463)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 64 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2457)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 65 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2461)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 66 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2459)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 67 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2455)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 68 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2458)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 69 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2451)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 70 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2452)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 71 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2451)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 72 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2449)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 73 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2449)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 74 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2445)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 75 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2444)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 76 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2442)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 77 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2441)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 78 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2444)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 79 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2453)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 80 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2453)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 81 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2450)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 82 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2451)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 83 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2448)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 84 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2447)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 85 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2444)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 86 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2442)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 87 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2442)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 88 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2446)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 89 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2459)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 90 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2446)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 91 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2451)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 92 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2457)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 93 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2457)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 94 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2466)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 95 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2456)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 96 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2454)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 97 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2436)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 98 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2449)\n",
            "VAL LOSS:\n",
            "=========================== EPOCH: 99 ===========================\n",
            "TRAIN LOSS:\n",
            "tensor(0.2445)\n",
            "VAL LOSS:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7516e40f2452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# visualizing predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"END\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b0ae28dad05b>\u001b[0m in \u001b[0;36mvis_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_gt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpred_masks_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# looping on batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b85e9a10adb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument weight in method wrapper_thnn_conv2d_forward)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF-G30oySA83"
      },
      "source": [
        "# **Visualizing Predictions vs Ground Truth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "VpMogAqiSH8w",
        "outputId": "ae2e919c-5dfd-4486-8398-56af0ee30c40"
      },
      "source": [
        "#saving model\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# torch.save(model, PATH)\n",
        "\n",
        "# model = UNet().to(device)\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# model = torch.load(PATH)\n",
        "\n",
        "vis_predictions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-01be3dc24d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model = torch.load(PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2ff3c1ada469>\u001b[0m in \u001b[0;36mvis_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_gt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpred_masks_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# looping on batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b85e9a10adb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument weight in method wrapper_thnn_conv2d_forward)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxCNIyFP1Hor"
      },
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}