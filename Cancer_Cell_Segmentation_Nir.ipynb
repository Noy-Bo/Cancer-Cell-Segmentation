{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cancer Cell Segmentation Nir.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iadNjTwWwwTY",
        "MzeZnwcM3BUg",
        "tB1G6fPU3N7I",
        "qgCVfGIl3jiZ",
        "rF-G30oySA83"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noy-Bo/Cancer-Cell-Segmentation/blob/master/Cancer_Cell_Segmentation_Nir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iadNjTwWwwTY"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "mounting drive, setting root path to PanNuke dataset, setting device to cuda, checking out GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9G0v8wsgvk",
        "outputId": "0c3810cc-461d-46a1-f62d-1aba6c647fe6"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JnPIOOtM-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c161638-38ed-4133-ca0c-f87a992b890a"
      },
      "source": [
        "import os\n",
        "root_path = '/content/gdrive/MyDrive/Colab/Cell Segmentation/' \n",
        "os.chdir(root_path)\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Cancer Cell Segmentation Nir.ipynb'   Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8t0kxy7Z3B",
        "outputId": "33549176-4963-41c9-bf6e-034ae0f114b7"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAtxgDvQ7eDJ",
        "outputId": "63a27721-0528-4bd4-a870-91e775509fc2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 22 16:37:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbWI64yG2wEw"
      },
      "source": [
        "# **Dataset**\n",
        "loading files, creating dataloaders, etc..\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y25bHcYNtcmu"
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "class PanNukeDataset(Dataset):\n",
        "    def  __init__(self, image_dir, masks_dir=None, cancer_types_dir=None, transform=None):\n",
        "        #self.image_dir = image_dir\n",
        "        #self.masks_dir = masks_dir\n",
        "        #self.cancer_types_dir = cancer_types_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Data is pickled into dictionaries ({'images': imgs, 'cancer_types': cancer_types, 'masks':masks}), let's open it up:\n",
        "        with open(image_dir, mode='rb') as f:  # The with just manages closing of files and etc once finished.\n",
        "            data_dict = pickle.load(f)  # load the original pickled dataset\n",
        "\n",
        "        self.images = data_dict['images']\n",
        "        self.cancer_types = data_dict['cancer_types']\n",
        "        self.masks = data_dict['masks']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    # returns images,masks   FOR NOW IT DOESN'T RETURN cancer_types!!!\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index, ...].astype(dtype=np.float32)\n",
        "        mask = self.masks[index, ...].astype(dtype=np.float32)\n",
        "        mask[mask > 0] = 1.0\n",
        "\n",
        "        # Set dimensions from 256x256xCH, to CHx256x256  - CHECK TO BE POSITIVE\n",
        "        mask = np.moveaxis(mask, -1, 0)\n",
        "        image = np.moveaxis(image, -1, 0)\n",
        "\n",
        "\n",
        "        if self.transform is not None :\n",
        "            augmentation = self.transform(image=image, mask=mask)\n",
        "            image = augmentation[\"image\"]\n",
        "            mask = augmentation[\"mask\"]\n",
        "\n",
        "        return torch.from_numpy(image),torch.from_numpy(mask)\n",
        "\n",
        "# Creating dataloaders\n",
        "def load_dataset(batch_size, shuffle_flag, num_workers, data_dir, transforms=None):\n",
        "  dataset = PanNukeDataset(data_dir)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_flag, num_workers=num_workers)\n",
        "  return data_loader\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzeZnwcM3BUg"
      },
      "source": [
        "# **Model**\n",
        "Micro-Net Model configuration (according to the paper, adjusted to 256x256 images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyi6s5FNtjrW"
      },
      "source": [
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as TNF\n",
        "import torch.nn.modules\n",
        "from torch import optim\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import tqdm\n",
        "\n",
        "# Small useful components:\n",
        "# this class is to be able to use TNF.interpole within nn.Sequential()\n",
        "class Interpolate(nn.Module):\n",
        "    def __init__(self, size, mode):\n",
        "        super(Interpolate, self).__init__()\n",
        "        self.interp = TNF.interpolate\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
        "\n",
        "# Create the Micro-Net components:\n",
        "class Group1_B1(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Group1_B1, self).__init__()\n",
        "\n",
        "        self.sub_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=5, stride=1, padding=0, bias=False), # kernel=5 since we start with 256 imgs, where in paper it's 252\n",
        "            nn.BatchNorm2d(64), # out_channels=64\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(64),  # REMOVE?\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        ) #124,124,64\n",
        "\n",
        "        self.sub_block2 = nn.Sequential(\n",
        "            Interpolate(size=(128,128),mode='bicubic'),\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(64),  # out_channels=64\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, orig_input):\n",
        "        sub_block1 = self.sub_block1(orig_input) # recall it outputs: B,CH,HEIGHT,WIDTH\n",
        "        sub_block2 = self.sub_block2(orig_input)\n",
        "        B1 = torch.cat((sub_block1,sub_block2), dim=1) # concat alongside channels dim'\n",
        "        return B1\n",
        "\n",
        "class Group1_B2(nn.Module):\n",
        "    def __init__(self, in_channels=128):\n",
        "        super(Group1_B2, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(  # gets 124^2, ch=128,   outputs: 60^2, ch=128\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=3, stride=1, padding=0, bias=True), # bias=True since no BN is applied.\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0, bias=True),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential( # gets 256^2, ch=3  outputs: 60^2, ch=128\n",
        "            Interpolate(size=(64, 64), mode='bicubic'),\n",
        "            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, B1_input, orig_input):\n",
        "        sub_block1 = self.sub_block1(B1_input)\n",
        "        sub_block2 = self.sub_block2(orig_input)\n",
        "        B2 = torch.cat((sub_block1, sub_block2), dim=1)  # concat alongside channels dim'\n",
        "        return B2\n",
        "\n",
        "class Group1_B3(nn.Module):\n",
        "    def __init__(self, in_channels=256):\n",
        "        super(Group1_B3, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(  # gets 60^2, ch=256,   outputs: 28^2, ch=256\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=0, bias=True), # bias=True since no BN is applied.\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=0, bias=True),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential( # gets 256^2, ch=3  outputs: 28^2, ch=256\n",
        "            Interpolate(size=(32, 32), mode='bicubic'),\n",
        "            nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, B2_input, orig_input):\n",
        "        sub_block1 = self.sub_block1(B2_input)\n",
        "        sub_block2 = self.sub_block2(orig_input)\n",
        "        B3 = torch.cat((sub_block1, sub_block2), dim=1)  # concat alongside channels dim'\n",
        "        return B3\n",
        "\n",
        "class Group1_B4(nn.Module):\n",
        "    def __init__(self, in_channels=512):\n",
        "        super(Group1_B4, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(  # gets 28^2, ch=512,   outputs: 12^2, ch=512\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=512, kernel_size=3, stride=1, padding=0, bias=True), # bias=True since no BN is applied.\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=0, bias=True),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential( # gets 256^2, ch=3  outputs: 12^2, ch=512\n",
        "            Interpolate(size=(16, 16), mode='bicubic'),\n",
        "            nn.Conv2d(in_channels=3, out_channels=512, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, B3_input, orig_input):\n",
        "        sub_block1 = self.sub_block1(B3_input)\n",
        "        sub_block2 = self.sub_block2(orig_input)\n",
        "        B4 = torch.cat((sub_block1, sub_block2), dim=1)  # concat alongside channels dim'\n",
        "        return B4\n",
        "\n",
        "class Group2_B5(nn.Module):\n",
        "    def __init__(self, in_channels=1024):\n",
        "        super(Group2_B5, self).__init__()\n",
        "        self.sub_block = nn.Sequential(  # gets 12^2, ch=1024,   outputs: 8^2, ch=2048\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=2048, kernel_size=3, stride=1, padding=0, bias=True), # bias=True since no BN is applied.\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=2048, out_channels=2048, kernel_size=3, stride=1, padding=0, bias=True),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, B4_input):\n",
        "        B5 = self.sub_block(B4_input)\n",
        "        return B5\n",
        "\n",
        "class Group3_Bi(nn.Module):\n",
        "    def __init__(self, in_channels_prev_b, in_channels_g1):\n",
        "        super(Group3_Bi, self).__init__()\n",
        "        # ------------------- UNSURE HERE REGARDING THE 1ST SUBBLOCK, WE DECONV UP TO 16 THEN CONV TWICE TO 8 THEN AGAIN DECONV UP TO 16?????\n",
        "        # First-part of the block:\n",
        "        self.sub_block1 = nn.Sequential(  # gets size^2, #channels, outputs (size*2)^2, #channels/2\n",
        "            nn.ConvTranspose2d(in_channels=in_channels_prev_b, out_channels=round(in_channels_prev_b / 2),kernel_size=2, stride=2, padding=0), # double x=h,w to 2x X 2x\n",
        "            nn.Conv2d(in_channels=round(in_channels_prev_b / 2), out_channels=round(in_channels_prev_b / 2), kernel_size=3, stride=1, padding=0), # turn to 2x-2 X 2x-2\n",
        "            # nn.BatchNorm2d(in_channels_prev_b/2),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=round(in_channels_prev_b / 2), out_channels=round(in_channels_prev_b / 2), kernel_size=3, stride=1, padding=0),  # turn to 2x -4 X 2x-4\n",
        "            # nn.BatchNorm2d(in_channels_prev_b/2),\n",
        "            nn.Tanh(),\n",
        "            nn.ConvTranspose2d(in_channels=round(in_channels_prev_b / 2), out_channels=round(in_channels_prev_b / 2), kernel_size=5, stride=1, padding=0),  # turn back to 2x X 2x,\n",
        "        )\n",
        "\n",
        "        # Mid-part of the block:\n",
        "        self.sub_block2 = nn.ConvTranspose2d(in_channels=in_channels_g1, out_channels=in_channels_g1, kernel_size=5, stride=1, padding=0) # it upsamples by 4 only\n",
        "\n",
        "        # Third-part of the block:\n",
        "        self.sub_block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=round(in_channels_g1*2), out_channels=in_channels_g1, kernel_size=3, stride=1, padding=1), # same conv\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, g1_input, prev_b_input):\n",
        "        sub_block1 = self.sub_block1(prev_b_input)\n",
        "        sub_block2 = self.sub_block2(g1_input)\n",
        "        sub_block3 = torch.cat((sub_block1, sub_block2), dim=1)  # concat alongside channels dim'\n",
        "        Bi = self.sub_block3(sub_block3)\n",
        "        return Bi\n",
        "\n",
        "class Group4_Pa1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Group4_Pa1, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2), #upsample by 2x\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0),  #UNLIKE THE PAPER, we'll use same convs, in order to get final-output= 256x256 as out data imgs\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential(\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            nn.Conv2d(in_channels=64, out_channels=6, kernel_size=1, stride=1, padding=0), #unlike paper ^^\n",
        "            #nn.Tanh(inplace=True), # Since it's output layer ^^..\n",
        "        )\n",
        "\n",
        "    def forward(self, b9_input):\n",
        "        x1 = self.sub_block1(b9_input) # this also goes onwards to Group5\n",
        "        pa1 = self.sub_block2(x1)\n",
        "        return pa1, x1\n",
        "\n",
        "class Group4_Pa2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Group4_Pa2, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=4), #upsample by 4x\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, stride=1, padding=0),  #UNLIKE THE PAPER, we'll use same convs, in order to get final-output= 256x256 as out data imgs\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential(\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            nn.Conv2d(in_channels=128, out_channels=6, kernel_size=1, stride=1, padding=0), #unlike paper ^^\n",
        "            #nn.Tanh(inplace=True), # Since it's output layer ^^..\n",
        "        )\n",
        "\n",
        "    def forward(self, b8_input):\n",
        "        x2 = self.sub_block1(b8_input) # this also goes onwards to Group5\n",
        "        pa2 = self.sub_block2(x2)\n",
        "        return pa2, x2\n",
        "\n",
        "class Group4_Pa3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Group4_Pa3, self).__init__()\n",
        "        self.sub_block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=8, stride=8), #upsample by 8x\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding=0),  #UNLIKE THE PAPER, we'll use same convs, in order to get final-output= 256x256 as out data imgs\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.sub_block2 = nn.Sequential(\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            nn.Conv2d(in_channels=256, out_channels=6, kernel_size=1, stride=1, padding=0), #unlike paper ^^\n",
        "            #nn.Tanh(inplace=True), # Since it's output layer ^^..\n",
        "        )\n",
        "\n",
        "    def forward(self, b7_input):\n",
        "        x3 = self.sub_block1(b7_input) # this also goes onwards to Group5\n",
        "        pa3 = self.sub_block2(x3)\n",
        "        return pa3, x3\n",
        "\n",
        "class Group5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Group5, self).__init__()\n",
        "        self.sub_block = nn.Sequential( #unlike the paper, the input for this stage is 256x256, 448(after concat)\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            nn.Conv2d(in_channels=448, out_channels=6, kernel_size=3, stride=1, padding=1), #unlike paper ^^\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        x = torch.cat((x1, x2, x3), dim=1) # concat x1,x2,x3 alongside channels dim'\n",
        "        p0 = self.sub_block(x)\n",
        "        return p0\n",
        "\n",
        "class MicroNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MicroNet, self).__init__()\n",
        "        self.group1_b1 = Group1_B1()\n",
        "        self.group1_b2 = Group1_B2()\n",
        "        self.group1_b3 = Group1_B3()\n",
        "        self.group1_b4 = Group1_B4()\n",
        "        self.group2 = Group2_B5()\n",
        "        self.group3_b6 = Group3_Bi(in_channels_prev_b=2048, in_channels_g1=1024)\n",
        "        self.group3_b7 = Group3_Bi(in_channels_prev_b=1024, in_channels_g1=512)\n",
        "        self.group3_b8 = Group3_Bi(in_channels_prev_b=512, in_channels_g1=256)\n",
        "        self.group3_b9 = Group3_Bi(in_channels_prev_b=256, in_channels_g1=128)\n",
        "        self.group4_pa1 = Group4_Pa1()\n",
        "        self.group4_pa2 = Group4_Pa2()\n",
        "        self.group4_pa3 = Group4_Pa3()\n",
        "        self.group5 = Group5()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Propagate through G1:\n",
        "        b1 = self.group1_b1(x)\n",
        "        b2 = self.group1_b2(b1, x)\n",
        "        b3 = self.group1_b3(b2, x)\n",
        "        b4 = self.group1_b4(b3, x)\n",
        "\n",
        "        # Propagate through G2:\n",
        "        b5 = self.group2(b4)\n",
        "\n",
        "        # Propagate through G3:\n",
        "        b6 = self.group3_b6(b4, b5)\n",
        "        b7 = self.group3_b7(b3, b6)\n",
        "        b8 = self.group3_b8(b2, b7)\n",
        "        b9 = self.group3_b9(b1, b8)\n",
        "\n",
        "        # Propagate through G4:\n",
        "        pa1, x1 = self.group4_pa1(b9)\n",
        "        pa2, x2 = self.group4_pa2(b8)\n",
        "        pa3, x3 = self.group4_pa3(b7)\n",
        "\n",
        "        # Propagate through G5:\n",
        "        p0 = self.group5(x1, x2, x3)\n",
        "\n",
        "        return p0, pa1, pa2, pa3  # recall that p0 = main output, pa1,pa2,pa3 = auxiliary outputs\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB1G6fPU3N7I"
      },
      "source": [
        "# **Train, Evaluation & Other model Utilities**\n",
        "loss functions configurations, train epoch function ..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsxsKcFftmZu"
      },
      "source": [
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "def train(model, loader, opt, criterion,scheduler, epoch):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # Train the model (turn training-mode on..)\n",
        "    model.train()\n",
        "\n",
        "    with tqdm.tqdm(total=len(loader), file=sys.stdout) as pbar:\n",
        "        for (images, masks) in loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # reinitialize gradients..\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Calculation of loss (according to paper):\n",
        "            p0, pa1, pa2, pa3 = model(images) # Pi.shape, 256x256x5\n",
        "            masks = torch.argmax(masks, dim=1)\n",
        "            #loss = criterion(output, masks)\n",
        "            l0 = criterion(p0, masks)\n",
        "            l1 = criterion(pa1, masks)\n",
        "            l2 = criterion(pa2, masks)\n",
        "            l3 = criterion(pa3, masks)\n",
        "            loss = l0+(l1+l2+l3)/epoch\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            #acc = calculate_accuracy(output, labels)\n",
        "\n",
        "            # update weights according to gradients\n",
        "            opt.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            #epoch_acc += acc.item\n",
        "\n",
        "            pbar.update()\n",
        "            pbar.set_description(f'train loss={loss.item():.3f}')\n",
        "\n",
        "        pbar.set_description(f'train loss={epoch_loss / len(loader):.3f}')\n",
        "    scheduler.step()\n",
        "\n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCVfGIl3jiZ"
      },
      "source": [
        "# **Main (training)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t83yC39t7sH",
        "outputId": "ae267c5b-1d26-4ae3-e1db-17ba85ed53bc"
      },
      "source": [
        "\n",
        "\n",
        "# Variables:\n",
        "BATCH_SIZE = 5\n",
        "NUM_WORKERS = 4\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE=0.001\n",
        "\n",
        "train_dir = 'Dataset/train_pickled_data'\n",
        "val_dir = 'Dataset/val_pickled_data'\n",
        "test_dir = 'Dataset/test_pickled_data'\n",
        "\n",
        "# Set up device:\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)\n",
        "\n",
        "# Grab loaders:\n",
        "train_loader = load_dataset(BATCH_SIZE, shuffle_flag=True, num_workers=NUM_WORKERS, data_dir=train_dir)\n",
        "val_loader = load_dataset(BATCH_SIZE, shuffle_flag=True, num_workers=NUM_WORKERS, data_dir=val_dir)\n",
        "test_loader = load_dataset(BATCH_SIZE, shuffle_flag=True, num_workers=NUM_WORKERS, data_dir=test_dir)\n",
        "\n",
        "\n",
        "model = MicroNet().to(device)\n",
        "summary(model, (3, 256, 256))\n",
        "\n",
        "# Define optimizer and criterion functions   - IMPROVE... LEARN HP'S\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-08)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5, last_epoch=-1, verbose=False)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch-%d: \" % (epoch))\n",
        "\n",
        "    train_start_time = time.monotonic()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, loss_func, scheduler, epoch+1)\n",
        "    train_end_time = time.monotonic()\n",
        "\n",
        "    # Save model\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict()\n",
        "    }\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    print(f\"train loss={train_loss}, epoch={epoch}\")\n",
        "\n",
        "    # val_start_time = time.monotonic()\n",
        "    # val_loss, val_acc = evaluate(model, val_loader, loss_func)\n",
        "    # val_end_time = time.monotonic()\n",
        "    #\n",
        "    # print(f\"train loss={train_loss}, epoch={epoch}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 252, 252]           4,800\n",
            "       BatchNorm2d-2         [-1, 64, 252, 252]             128\n",
            "              Tanh-3         [-1, 64, 252, 252]               0\n",
            "            Conv2d-4         [-1, 64, 248, 248]         102,400\n",
            "       BatchNorm2d-5         [-1, 64, 248, 248]             128\n",
            "              Tanh-6         [-1, 64, 248, 248]               0\n",
            "         MaxPool2d-7         [-1, 64, 124, 124]               0\n",
            "       Interpolate-8          [-1, 3, 128, 128]               0\n",
            "            Conv2d-9         [-1, 64, 126, 126]           1,728\n",
            "      BatchNorm2d-10         [-1, 64, 126, 126]             128\n",
            "             Tanh-11         [-1, 64, 126, 126]               0\n",
            "           Conv2d-12         [-1, 64, 124, 124]          36,864\n",
            "             Tanh-13         [-1, 64, 124, 124]               0\n",
            "        Group1_B1-14        [-1, 128, 124, 124]               0\n",
            "           Conv2d-15        [-1, 128, 122, 122]         147,584\n",
            "             Tanh-16        [-1, 128, 122, 122]               0\n",
            "           Conv2d-17        [-1, 128, 120, 120]         147,584\n",
            "             Tanh-18        [-1, 128, 120, 120]               0\n",
            "        MaxPool2d-19          [-1, 128, 60, 60]               0\n",
            "      Interpolate-20            [-1, 3, 64, 64]               0\n",
            "           Conv2d-21          [-1, 128, 62, 62]           3,456\n",
            "      BatchNorm2d-22          [-1, 128, 62, 62]             256\n",
            "             Tanh-23          [-1, 128, 62, 62]               0\n",
            "           Conv2d-24          [-1, 128, 60, 60]         147,456\n",
            "             Tanh-25          [-1, 128, 60, 60]               0\n",
            "        Group1_B2-26          [-1, 256, 60, 60]               0\n",
            "           Conv2d-27          [-1, 256, 58, 58]         590,080\n",
            "             Tanh-28          [-1, 256, 58, 58]               0\n",
            "           Conv2d-29          [-1, 256, 56, 56]         590,080\n",
            "             Tanh-30          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-31          [-1, 256, 28, 28]               0\n",
            "      Interpolate-32            [-1, 3, 32, 32]               0\n",
            "           Conv2d-33          [-1, 256, 30, 30]           6,912\n",
            "      BatchNorm2d-34          [-1, 256, 30, 30]             512\n",
            "             Tanh-35          [-1, 256, 30, 30]               0\n",
            "           Conv2d-36          [-1, 256, 28, 28]         589,824\n",
            "             Tanh-37          [-1, 256, 28, 28]               0\n",
            "        Group1_B3-38          [-1, 512, 28, 28]               0\n",
            "           Conv2d-39          [-1, 512, 26, 26]       2,359,808\n",
            "             Tanh-40          [-1, 512, 26, 26]               0\n",
            "           Conv2d-41          [-1, 512, 24, 24]       2,359,808\n",
            "             Tanh-42          [-1, 512, 24, 24]               0\n",
            "        MaxPool2d-43          [-1, 512, 12, 12]               0\n",
            "      Interpolate-44            [-1, 3, 16, 16]               0\n",
            "           Conv2d-45          [-1, 512, 14, 14]          13,824\n",
            "      BatchNorm2d-46          [-1, 512, 14, 14]           1,024\n",
            "             Tanh-47          [-1, 512, 14, 14]               0\n",
            "           Conv2d-48          [-1, 512, 12, 12]       2,359,296\n",
            "             Tanh-49          [-1, 512, 12, 12]               0\n",
            "        Group1_B4-50         [-1, 1024, 12, 12]               0\n",
            "           Conv2d-51         [-1, 2048, 10, 10]      18,876,416\n",
            "             Tanh-52         [-1, 2048, 10, 10]               0\n",
            "           Conv2d-53           [-1, 2048, 8, 8]      37,750,784\n",
            "             Tanh-54           [-1, 2048, 8, 8]               0\n",
            "        Group2_B5-55           [-1, 2048, 8, 8]               0\n",
            "  ConvTranspose2d-56         [-1, 1024, 16, 16]       8,389,632\n",
            "           Conv2d-57         [-1, 1024, 14, 14]       9,438,208\n",
            "             Tanh-58         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-59         [-1, 1024, 12, 12]       9,438,208\n",
            "             Tanh-60         [-1, 1024, 12, 12]               0\n",
            "  ConvTranspose2d-61         [-1, 1024, 16, 16]      26,215,424\n",
            "  ConvTranspose2d-62         [-1, 1024, 16, 16]      26,215,424\n",
            "           Conv2d-63         [-1, 1024, 16, 16]      18,875,392\n",
            "             Tanh-64         [-1, 1024, 16, 16]               0\n",
            "        Group3_Bi-65         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-66          [-1, 512, 32, 32]       2,097,664\n",
            "           Conv2d-67          [-1, 512, 30, 30]       2,359,808\n",
            "             Tanh-68          [-1, 512, 30, 30]               0\n",
            "           Conv2d-69          [-1, 512, 28, 28]       2,359,808\n",
            "             Tanh-70          [-1, 512, 28, 28]               0\n",
            "  ConvTranspose2d-71          [-1, 512, 32, 32]       6,554,112\n",
            "  ConvTranspose2d-72          [-1, 512, 32, 32]       6,554,112\n",
            "           Conv2d-73          [-1, 512, 32, 32]       4,719,104\n",
            "             Tanh-74          [-1, 512, 32, 32]               0\n",
            "        Group3_Bi-75          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-76          [-1, 256, 64, 64]         524,544\n",
            "           Conv2d-77          [-1, 256, 62, 62]         590,080\n",
            "             Tanh-78          [-1, 256, 62, 62]               0\n",
            "           Conv2d-79          [-1, 256, 60, 60]         590,080\n",
            "             Tanh-80          [-1, 256, 60, 60]               0\n",
            "  ConvTranspose2d-81          [-1, 256, 64, 64]       1,638,656\n",
            "  ConvTranspose2d-82          [-1, 256, 64, 64]       1,638,656\n",
            "           Conv2d-83          [-1, 256, 64, 64]       1,179,904\n",
            "             Tanh-84          [-1, 256, 64, 64]               0\n",
            "        Group3_Bi-85          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-86        [-1, 128, 128, 128]         131,200\n",
            "           Conv2d-87        [-1, 128, 126, 126]         147,584\n",
            "             Tanh-88        [-1, 128, 126, 126]               0\n",
            "           Conv2d-89        [-1, 128, 124, 124]         147,584\n",
            "             Tanh-90        [-1, 128, 124, 124]               0\n",
            "  ConvTranspose2d-91        [-1, 128, 128, 128]         409,728\n",
            "  ConvTranspose2d-92        [-1, 128, 128, 128]         409,728\n",
            "           Conv2d-93        [-1, 128, 128, 128]         295,040\n",
            "             Tanh-94        [-1, 128, 128, 128]               0\n",
            "        Group3_Bi-95        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-96         [-1, 64, 256, 256]          32,832\n",
            "           Conv2d-97         [-1, 64, 256, 256]           4,160\n",
            "             Tanh-98         [-1, 64, 256, 256]               0\n",
            "        Dropout2d-99         [-1, 64, 256, 256]               0\n",
            "          Conv2d-100          [-1, 6, 256, 256]             390\n",
            "      Group4_Pa1-101  [[-1, 6, 256, 256], [-1, 64, 256, 256]]               0\n",
            " ConvTranspose2d-102        [-1, 128, 256, 256]         524,416\n",
            "          Conv2d-103        [-1, 128, 256, 256]          16,512\n",
            "            Tanh-104        [-1, 128, 256, 256]               0\n",
            "       Dropout2d-105        [-1, 128, 256, 256]               0\n",
            "          Conv2d-106          [-1, 6, 256, 256]             774\n",
            "      Group4_Pa2-107  [[-1, 6, 256, 256], [-1, 128, 256, 256]]               0\n",
            " ConvTranspose2d-108        [-1, 256, 256, 256]       8,388,864\n",
            "          Conv2d-109        [-1, 256, 256, 256]          65,792\n",
            "            Tanh-110        [-1, 256, 256, 256]               0\n",
            "       Dropout2d-111        [-1, 256, 256, 256]               0\n",
            "          Conv2d-112          [-1, 6, 256, 256]           1,542\n",
            "      Group4_Pa3-113  [[-1, 6, 256, 256], [-1, 256, 256, 256]]               0\n",
            "       Dropout2d-114        [-1, 448, 256, 256]               0\n",
            "          Conv2d-115          [-1, 6, 256, 256]          24,198\n",
            "          Group5-116          [-1, 6, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 206,070,040\n",
            "Trainable params: 206,070,040\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 88078570.63\n",
            "Params size (MB): 786.09\n",
            "Estimated Total Size (MB): 88079357.48\n",
            "----------------------------------------------------------------\n",
            "Epoch-0: \n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss=5.625:  63%|██████▎   | 800/1265 [08:13<04:47,  1.62it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF-G30oySA83"
      },
      "source": [
        "# **Visualizing Predictions vs Ground Truth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "VpMogAqiSH8w",
        "outputId": "ae2e919c-5dfd-4486-8398-56af0ee30c40"
      },
      "source": [
        "#saving model\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# torch.save(model, PATH)\n",
        "\n",
        "# model = UNet().to(device)\n",
        "# PATH = root_path + \"/model_UNet.pt\"\n",
        "# model = torch.load(PATH)\n",
        "\n",
        "vis_predictions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-01be3dc24d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model = torch.load(PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2ff3c1ada469>\u001b[0m in \u001b[0;36mvis_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvis_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_gt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpred_masks_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gt_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# looping on batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b85e9a10adb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument weight in method wrapper_thnn_conv2d_forward)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxCNIyFP1Hor"
      },
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}